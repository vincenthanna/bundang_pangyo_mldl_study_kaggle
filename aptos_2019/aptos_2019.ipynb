{"cells":[{"metadata":{},"cell_type":"markdown","source":"# APTOS 2019 Blindness Detection\n\n\n다음 커널을 base로 작성하였습니다.\n\n\nhttps://www.kaggle.com/carlolepelaars/efficientnetb5-with-keras-aptos-2019/data"},{"metadata":{},"cell_type":"markdown","source":"상수 정의"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os.path\n\n# image directory path\n#../input/aptos-train-dataset/aptos-train-images/aptos-train-images/\n\n#original data : ../input/aptos2019-blindness-detection\nTRAIN_DATA_PATH = \"../input/aptos-train-dataset\"\nTEST_DATA_PATH = \"../input/aptos2019-blindness-detection\"\nPREPROCESSED_IMAGE_PATH = \"./preprocessed\"\nMODEL_PATH = \"./models\"\n\nTRAIN_CSV_FILE_PATH = os.path.join(TRAIN_DATA_PATH, \"train.csv\")\nTRAIN_IMAGE_FILE_PATH = \"../input/aptos-train-dataset/aptos-train-images/aptos-train-images\"\n\nTEST_CSV_FILE_PATH = \"../input/aptos2019-blindness-detection/test.csv\"\nTEST_IMAGE_FILE_PATH = \"../input/aptos2019-blindness-detection/test_images\"\n\nFOLDED_DATASETS_PATH = \"../input/APTOS_data_files\"\n\n\"\"\"\n전체 커널이 제대로 돌아기는지 확인할 때 사용한다.\nsubmission이 정상적으로 진행되는지까지 학인\n\"\"\"\nCHECK_KERNEL_VALID = True\n\nIMG_WIDTH = 224\nIMG_HEIGHT = 224\nIMG_CHANNELS = 3\n\nBATCH_SIZE = 32\n\nNUM_FOLDS = 6\n\nEPOCHS = 40\nif CHECK_KERNEL_VALID:\n    EPOCHS = 6\n\nGENERATE_WEIGHTS = True\n\nASSIGNED_FOLD_JOBS = [x for x in range(NUM_FOLDS)]\n\ndef constants_check():\n    pd.read_csv(TRAIN_CSV_FILE_PATH)\n    pd.read_csv(TEST_CSV_FILE_PATH)\n    \n    train_imgs_count = len(os.listdir(TRAIN_IMAGE_FILE_PATH))\n    test_imgs_count = len(os.listdir(TEST_IMAGE_FILE_PATH))\n                           \n    print(\"train images : \", train_imgs_count)\n    print(\"test images : \", test_imgs_count)\n    \n    assert(train_imgs_count > 100)\n    assert(test_imgs_count > 100)\n    \nconstants_check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport shutil\n\nif os.path.exists(MODEL_PATH) == False:\n    Path(MODEL_PATH).mkdir(parents=True, exist_ok=True)\n\n\n# weight를 생성하려는 목적이 아니면 weight파일을 미리 복사해 둔다.\n\npre_models_path = \"../input/aptos-data-files\"\n\nif os.path.exists(pre_models_path):\n    for fname in os.listdir(pre_models_path):\n        filepath = os.path.join(pre_models_path, fname)\n        print(filepath)\n        if os.path.isfile(filepath):\n            if GENERATE_WEIGHTS == True:\n                if fname.find(\"h5\") > 0:\n                    continue\n            destfilepath = os.path.join(MODEL_PATH, fname)\n            print(\"copy file \", filepath, \" to \", destfilepath)\n            shutil.copy(filepath, destfilepath)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_CSV_FILE_PATH)\ndf_test = pd.read_csv(TEST_CSV_FILE_PATH)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n#from PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nn = 3\n\nfix, ax = plt.subplots(n, n, figsize = (16, 16))\naxidx = 0\n\ndf_sample = df_train.sample(n * n)\nfor idx, row in df_sample.iterrows():\n    imgpath = os.path.join(TRAIN_IMAGE_FILE_PATH, row['id_code'])\n    \n    im = cv2.imread(imgpath)\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = cv2.addWeighted(im, 4, cv2.GaussianBlur(im, (0,0) ,10), -4, 128)\n\n    ax[int(axidx / n)][axidx % n].imshow(im)\n    axidx += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport cv2\nimport numpy as np\n\nfrom PIL import Image, ImageChops\n\ndefault_ratio = 1.0\n\ndef crop_image_from_gray(img, tol=7):\n    \"\"\"\n    Applies masks to the orignal image and \n    returns the a preprocessed image with \n    3 channels\n    \"\"\"\n    # If for some reason we only have two channels\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    # If we have a normal RGB images\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n\n#from : https://www.kaggle.com/carlolepelaars/efficientnetb5-with-keras-aptos-2019/data\ndef preprocess_image(path):\n    \"\"\"\n    The whole preprocessing pipeline:\n    1. Read in image\n    2. Apply masks\n    3. Resize image to desired size\n    4. Add Gaussian noise to increase Robustness\n    \"\"\"\n    \n    im = cv2.imread(path)\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = crop_image_from_gray(im)\n    im = cv2.addWeighted(im, 4, cv2.GaussianBlur(im, (0,0) ,10), -4, 128)\n    im = cv2.resize(im, (IMG_WIDTH, IMG_HEIGHT))\n    return im\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fix, ax = plt.subplots(n, n, figsize = (20, 20))\n\naxidx = 0    \nfor idx, row in df_sample.iterrows():\n    filename = row['id_code']\n    imgpath = os.path.join(TRAIN_IMAGE_FILE_PATH, filename)\n    im = preprocess_image(imgpath)\n    ax[int(axidx / (n))][axidx % n].imshow(im)\n    ax[int(axidx / (n))][axidx % n].set_title(row['id_code'])\n    axidx += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nsys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n\nfrom efficientnet import EfficientNetB5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds_and_labels(model, generator):\n    \"\"\"\n    Get predictions and labels from the generator\n    \"\"\"\n    preds = []\n    labels = []\n    for _ in range(int(np.ceil(generator.samples / BATCH_SIZE))):\n        x, y = next(generator)\n        preds.append(model.predict(x))\n        labels.append(y)\n    # Flatten list of numpy arrays\n    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation\n\nsubmission 평가가 QWK(Quadratic Weighted Kappa) 기반으로 이루어진다.\n\n### Cohen's Kappa\n두 연구자간 동일한 결과를 내놓는지를 수치화하는 방법이다. <br>\n더 자세히 설명하면, 두 연구자 간 일치한 결과 중에서 우연히 일치할 가능성를 제외하고, 실제로 평가가 일치한 결과가 어느 정도인지 보여주는 지표이다.<br>\nnominal(category간 거리가 같은)한 범주에 사용된다.\n\n### Cohen's weighted Kappa\nCohen's Kappa와는 다르게, ordinal(순서가 있는, 예를 들어 관절염의 5 단계(1:없음, 2:경증 ... 5:심각) 등을 표현 시) 변수를 대상으로 할 경우에는 Cohen's weighted Kappa를 사용한다. <br>\n순서(또는 단계)가 있는 변수를 판단하므로 범주(카테고리)간 거리는 서로 다르고, 두 연구자간 결과가 다를 경우에도 다름의 크기에 가중치 차이가 있을 것이다.<br>\n이런 식으로 각각 다른 비중(weight)를 두어 불일치 정도를 평가하는 것이다.\n\n각 범주간 차이에 비중을 부여하는 방법으로는 값의 차이를 그대로 사용하는 linear 방법과, 제곱해서 사용하는 quadratic 방법이 있다.<br>\n(1과 3의 차이 : linear = 2, quadratic = 4)\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"QWK가 개선되는 경우 모델을 저장하는 custom callback을 정의해서 train시 사용한다.\n\n> **sklearn.metrics.cohen_kappa_score(y1, y2, labels=None, weights=None, sample_weight=None)**\n\nCohen’s kappa: a statistic that measures inter-annotator agreement.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\nfrom keras.callbacks import Callback\n\nclass Metrics(Callback):\n    \"\"\"\n    A custom Keras callback for saving the best model\n    according to the Quadratic Weighted Kappa (QWK) metric\n    \"\"\"\n    def __init__(self, model, val_generator, model_save_filepath):\n        self.model = model\n        self.val_generator = val_generator\n        self.model_save_filepath = model_save_filepath\n        \n    def on_train_begin(self, logs={}):\n        \"\"\"\n        Initialize list of QWK scores on validation data\n        \"\"\"\n        self.val_kappas = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        \"\"\"\n        Gets QWK score on the validation data\n        \"\"\"\n        # Get predictions and convert to integers\n        y_pred, labels = get_preds_and_labels(self.model, self.val_generator)\n        y_pred = np.rint(y_pred).astype(np.uint8).clip(0, 4)\n        # We can use sklearns implementation of QWK straight out of the box\n        # as long as we specify weights as 'quadratic'\n        _val_kappa = cohen_kappa_score(labels, y_pred, weights='quadratic')\n        self.val_kappas.append(_val_kappa)\n        print(f\"val_kappa: {round(_val_kappa, 4)}\")\n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save(self.model_save_filepath)\n        return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{},"cell_type":"markdown","source":"callback 정의"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n\ndef get_callbacks(model, val_generator, model_save_filepath):\n    # Monitor MSE to avoid overfitting and save best model\n    es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=15)\n    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=4)\n    km = Metrics(model, val_generator, model_save_filepath)\n    return [es, lr, km]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EfficientNetB5을 base로 하고, 출력은 linear로 뽑는다.<br>\noutput이 nomial하기 때문에 linear로 출력하고 loss는 MSE로 한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nfrom keras.activations import elu\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n\n\ndef build_model_effnet_b5(load_weights = True):\n    \"\"\"\n    A custom implementation of EfficientNetB5\n    for the APTOS 2019 competition\n    (Regression)\n    \"\"\"\n    \n    # Load in EfficientNetB5\n    effnet_b5 = EfficientNetB5(weights=None,\n                        include_top=False,\n                        input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n    if load_weights == True:\n        effnet_b5.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')\n    \n    model = Sequential()\n    model.add(effnet_b5)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation=elu))\n    model.add(Dense(1, activation=\"linear\"))\n    model.compile(loss='mse',\n                  optimizer=Adam(0.0001), \n                  metrics=['mse', 'acc'])\n    print(model.summary())\n    return model\n\nmodels_list = [\"effnet_b5\"]\n\ndef get_model(m, load_weights = True):\n    if m == \"effnet_b5\":\n        return build_model_effnet_b5(load_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_total_batch(num_samples, batch_size):    \n    if (num_samples % batch_size) > 0 :\n        return (num_samples // batch_size) + 1\n    else :\n        return num_samples // batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.backend.tensorflow_backend import set_session\nfrom keras.backend.tensorflow_backend import clear_session\nfrom keras.backend.tensorflow_backend import get_session\n\n# Reset Keras Session\ndef reset_keras():\n    sess = get_session()\n    clear_session()\n    sess.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport psutil \n\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\ndef train_one_fold(model_name, fold_index):\n    model = get_model(model_name)\n\n    model_save_filename = (\"%s_%d.h5\" % (model_name , fold_index))\n    model_save_filepath = os.path.join(MODEL_PATH, model_save_filename)\n\n    # load folded dataframe\n    df_train_filename = (\"fold_%d_train.csv\" % fold_index)\n    df_val_filename = (\"fold_%d_val.csv\" % fold_index)\n\n    dataframe_train = pd.read_csv(os.path.join(MODEL_PATH, df_train_filename))\n    dataframe_val = pd.read_csv(os.path.join(MODEL_PATH, df_val_filename))\n\n    # for test :\n    if CHECK_KERNEL_VALID == True:\n        dataframe_train = dataframe_train.sample(int(dataframe_train.shape[0] / 80))\n        dataframe_val = dataframe_val.sample(int(dataframe_val.shape[0] / 80))\n        \n    print(\"Data Counts: train=\", dataframe_train.shape[0], \" validation=\", dataframe_val.shape[0])\n    \n    # Add Image augmentation to our generator\n    train_datagen = ImageDataGenerator(rescale = 1./255,\n                                       rotation_range=360,\n                                       horizontal_flip=True,\n                                       vertical_flip=True)\n\n    val_datagen = ImageDataGenerator(rescale = 1./255)\n\n    # Use the dataframe to define train and validation generators\n    train_generator = train_datagen.flow_from_dataframe(dataframe_train, \n                                                        x_col='id_code', \n                                                        y_col='diagnosis',\n                                                        directory = TRAIN_IMAGE_FILE_PATH,\n                                                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                        batch_size=BATCH_SIZE,\n                                                        class_mode='other',\n                                                        preprocessing_function=preprocess_image)\n\n    val_generator = val_datagen.flow_from_dataframe(dataframe_val, \n                                                      x_col='id_code',\n                                                      y_col='diagnosis',\n                                                      directory = TRAIN_IMAGE_FILE_PATH,\n                                                      target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                      batch_size=BATCH_SIZE,\n                                                      class_mode='other',\n                                                      preprocessing_function=preprocess_image)\n    if GENERATE_WEIGHTS == True:\n        if os.path.exists(model_save_filepath) == True:\n            os.remove(model_save_filepath)\n\n    # skip if weight file exists\n    if os.path.exists(model_save_filepath) == True:\n        print(\">>>>>>>>>>\", model_save_filepath, \" already trained... skip!\")\n        return\n\n    train_steps = get_total_batch(train_generator.samples, BATCH_SIZE)\n    val_steps = get_total_batch(val_generator.samples, BATCH_SIZE)\n    print(\"Steps : train=\", train_steps, \" validation=\", val_steps)\n\n    # make callbacks\n    callbacks = get_callbacks(model=model, val_generator=val_generator, model_save_filepath=model_save_filepath)\n\n    # First training phase (train top layer)\n    model.fit_generator(train_generator,\n                        steps_per_epoch = train_steps,\n                        epochs = EPOCHS,\n                        validation_data = val_generator,\n                        validation_steps = val_steps,\n                        callbacks = callbacks)\n    \n    \n    \n    \ndef train_models():\n    global models_list\n    for _m in models_list:\n        for fold_index in ASSIGNED_FOLD_JOBS:\n            \n            print(\"\")\n            print(\"========================================================\")\n            print(\"Model : \", _m, \"/ fold : \", fold_index)\n            print(\"========================================================\")\n            print(\"\")\n            \n            train_one_fold(_m, fold_index)\n                        \n            # clear used memory\n            K.clear_session()\n            for i in range(20):\n                gc.collect()            \n            \n\ntrain_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{},"cell_type":"markdown","source":"최고 QWK값을 기록한 weight를 사용한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndef load_sub_models():\n    sub_models = []\n    for _m in models_list:\n        print(\"Model \", _m, \" : \")\n        for _, _, filenames in os.walk(MODEL_PATH):\n            for fname in filenames:\n                if fname.find(_m) >= 0 and fname.find(\".h5\") >= 0:                    \n                    model = get_model(_m, load_weights = False)\n                    \n                    fpath = os.path.join(MODEL_PATH, fname)\n                    print(\">>>>>>>>>> Loading weight file :\", fpath)\n                    model.load_weights(fpath)\n                    \n                    sub_models.append(model)\n                    \n    return sub_models\n\nsub_models = load_sub_models()\n'''\n\ndef get_sub_model(model_name, fold_index):\n    \n    model_save_filename = (\"%s_%d.h5\" % (model_name , fold_index))\n    model_save_filepath = os.path.join(MODEL_PATH, model_save_filename)\n    \n    model = get_model(m, load_weights = False)\n    model.load_weights(model_save_filepath)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport scipy as sp\nfrom functools import partial\n\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa score\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \"\"\"\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \"\"\"\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit([0.2, 3.2, 4.8], [0, 3, 4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\n# Preprocess test images\nN = df_test.shape[0]\nx_test = np.empty((N, IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS), dtype=np.uint8)\nfor i, image_id in enumerate(df_test['id_code']):\n    x_test[i, :, :, :] = preprocess_image(f'{TEST_IMAGE_FILE_PATH}/{image_id}.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TTA_STEPS = 4\npredictions = []\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\n# for model in submodels:\n#     flow = tta_datagen.flow_from_dataframe(df_test,\n#                                             x_col='id_code', \n#                                             y_col='diagnosis',\n#                                             directory = TEST_IMAGE_FILE_PATH,\n#                                             target_size=(IMG_WIDTH, IMG_HEIGHT),\n#                                             batch_size=BATCH_SIZE,\n#                                             class_mode='other',\n#                                             preprocessing_function=preprocess_image)\n#     preds = []\n    \n#     steps = get_total_batch(df_test.shape[0], BATCH_SIZE)\n    \n#     for i in range(TTA_STEPS):\n#         flow.reset()\n#         pred = model.predict_generator(generator = flow, steps = steps, verbose = 1)\n#         preds.append(pred)\n        \n#     pred_tta = np.mean(preds, axis=0)\n#     prediction.append(pred_tta)\n\nfor _m in models_list:    \n    for fold_index in ASSIGNED_FOLD_JOBS:\n        \n        # Add Image augmentation to our generator\n        tta_datagen = ImageDataGenerator(rotation_range=360,\n                                         horizontal_flip=True,\n                                         vertical_flip=True,\n                                         validation_split=0.15)\n\n        model = get_sub_model(_m, fold_index)\n        flow = tta_datagen.flow_from_dataframe(df_test,\n                                            x_col='id_code', \n                                            y_col='diagnosis',\n                                            directory = TEST_IMAGE_FILE_PATH,\n                                            target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                            batch_size=BATCH_SIZE,\n                                            class_mode='other',\n                                            preprocessing_function=preprocess_image)\n        preds = []\n    \n        steps = get_total_batch(df_test.shape[0], BATCH_SIZE)\n    \n        for i in range(TTA_STEPS):\n            flow.reset()\n            pred = model.predict_generator(generator = flow,\n                                           steps = steps,\n                                           verbose = 1)\n            preds.append(pred)\n        \n        pred_tta = np.mean(preds, axis=0)\n        prediction.append(pred_tta)\n        \n        # clear used memory\n        K.clear_session()\n        for i in range(20):\n            gc.collect() \n    \npred = np.mean(prediction, axis=0)\n\ny_test = optR.predict(y_test, coefficients).astype(int)\ndf_test['diagnosis'] = y_test\n# Remove .png, .jpeg, .jpg from ids\ndf_test['id_code'] = df_test['id_code'].str.replace(r'.png$', '')\ndf_test['id_code'] = df_test['id_code'].str.replace(r'.jpeg$', '')\ndf_test['id_code'] = df_test['id_code'].str.replace(r'.jpg$', '')\ntest_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TTA_STEPS = 4\npredictions = []\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Add Image augmentation to our generator\ntta_datagen = ImageDataGenerator(rotation_range=360,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   validation_split=0.15)\n\nfor model in submodels:\n    flow = tta_datagen.flow_from_dataframe(df_test,\n                                            x_col='id_code', \n                                            y_col='diagnosis',\n                                            directory = TEST_IMAGE_FILE_PATH,\n                                            target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                            batch_size=BATCH_SIZE,\n                                            class_mode='other',\n                                            preprocessing_function=preprocess_image)\n    preds = []\n    \n    steps = get_total_batch(df_test.shape[0], BATCH_SIZE)\n    \n    for i in range(TTA_STEPS):\n        flow.reset()\n        pred = model.predict_generator(generator = flow, steps = steps, verbose = 1)\n        preds.append(pred)\n        \n    pred_tta = np.mean(preds, axis=0)\n    prediction.append(pred_tta)\n    \npred = np.mean(prediction, axis=0)\n\ny_test = optR.predict(y_test, coefficients).astype(int)\ndf_test['diagnosis'] = y_test\n# Remove .png, .jpeg, .jpg from ids\ndf_test['id_code'] = df_test['id_code'].str.replace(r'.png$', '')\ndf_test['id_code'] = df_test['id_code'].str.replace(r'.jpeg$', '')\ndf_test['id_code'] = df_test['id_code'].str.replace(r'.jpg$', '')\ntest_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}